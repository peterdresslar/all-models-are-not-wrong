{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models Are Not Wrong\n",
    "## Peter Dresslar, Arizona State University\n",
    "- CAS 520 Bergin\n",
    "- CAS 598 Damerow\n",
    "- CAS 598 Wei\n",
    "\n",
    "This week, with the start of two foundational Masters-level Complexity Sciences courses at Arizona State University, the same quotation was shared in each as the central basis of the week's discussion to open our exploration of complexity modeling.\n",
    "\n",
    "\"All models are wrong. Some are useful.\"[^1]\n",
    "\n",
    "While this famous saying from the statistician George Box is one of the more widely-known commentaries on modeling discipline, one might wonder if, speaking at least from a contemporary perspective, it is really the right place to start when embarking on an exploration in complexity science.\n",
    "\n",
    "- Before we further explore the quotation by Box, we might first read it in the context in which it was most recently published.\n",
    "\n",
    ">[Quote]\n",
    "\n",
    "- Clearly Box was just making a point about the difficulty of accurate representations of reality, and emphasizing the importance of certain lines of statistical work---some of which, we might observe, were precisely the kinds of work for which he was famous.\n",
    "\n",
    "- Many academics have commented on the quotation over the years, with at least a few of them finding it unhelpful or misleading.\n",
    "\n",
    ">[Quote]\n",
    "\n",
    "Now, fifty years after Box's first utterance of the saying, we are unquestionably living in a new regime of thinking, or, in some estimates, a regime of un-thinking. Readers will need little reminder of society's changing attitudes toward basic sciences and plain empiricism. \n",
    "\n",
    "And, whether or not Box's quotation is useful... it is certainly wrong.\n",
    "\n",
    "Let's demonstrate this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "however_many_years = 9999999\n",
    "todays_year = datetime.datetime.now().year\n",
    "start_year = todays_year  # or feel free to choose your own\n",
    "dt = 8  # years to step\n",
    "\n",
    "for year in range(start_year, start_year + however_many_years, dt):\n",
    "    if year % 4 == 0 and (year % 100 != 0 or year % 400 == 0):\n",
    "        print(f\"\\r{year} is a leap year\", end=\"\", flush=True) # no \\n\n",
    "    else:\n",
    "        print(f\"\\r{year} is not a leap year\", end=\"\", flush=True) # no \\n\n",
    "    time.sleep(1)  #  Seconds. For human-utility purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is completly discrete. It is a flawless reprentation of the Gregorian calendar, a real-world, everyday system used by billions of people. The model has faint but non-zero usefulness. \n",
    "\n",
    "And, this model is not wrong.\n",
    "\n",
    "But what about more complex, real-world models?\n",
    "\n",
    "<p align=\"center\">. . . </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GLMM is a wolf model\n",
    "- Proposed by\n",
    "- It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Mixed Linear Model Regression Results\n",
      "=======================================================\n",
      "Model:            MixedLM Dependent Variable: pups_born\n",
      "No. Observations: 10      Method:             REML     \n",
      "No. Groups:       6       Scale:              1.3098   \n",
      "Min. group size:  1       Log-Likelihood:     -18.1904 \n",
      "Max. group size:  2       Converged:          Yes      \n",
      "Mean group size:  1.7                                  \n",
      "--------------------------------------------------------\n",
      "           Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept  1.660     4.515  0.368  0.713  -7.188  10.509\n",
      "body_mass  0.073     0.118  0.621  0.535  -0.158   0.305\n",
      "Group Var  0.981     1.925                              \n",
      "=======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GLMM Simplified\n",
    "# See, for instance, https://github.com/junpenglao/GLMM-in-Python/blob/master/GLMM_in_python.ipynb\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "# Example wolf data, intended to mimic the Stahler data\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'pups_born': [5, 4, 6, 7, 3, 2, 6, 4, 5, 3],\n",
    "    'body_mass': [34, 37, 42, 47, 29, 44, 39, 36, 41, 33],\n",
    "    'pack_id': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E', 'F']\n",
    "})\n",
    "\n",
    "# Fit a Generalized Linear Mixed Model (GLMM)\n",
    "model = smf.mixedlm('pups_born ~ body_mass', \n",
    "                    data=data, \n",
    "                    groups=data['pack_id'])  # note that Stahler2013 uses a Poisson GLMM; here we simplify to Gaussian distribution for simplicity\n",
    "\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper then goes on to present copious real-world data, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
